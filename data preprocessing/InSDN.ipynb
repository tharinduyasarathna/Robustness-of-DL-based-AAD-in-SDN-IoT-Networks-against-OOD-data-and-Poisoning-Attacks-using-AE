{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811bb9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from unidecode import unidecode\n",
    "\n",
    "import pickle # saving and loading trained model\n",
    "from os import path\n",
    "\n",
    "# importing required libraries for normalizing data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# importing library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score # for calculating accuracy of model\n",
    "from sklearn.model_selection import train_test_split # for splitting the dataset for training and testing\n",
    "from sklearn.metrics import classification_report # for generating a classification report of model\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow  as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Activation\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6efc73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "path = r'D:/PhD exp/Datasets/InSDN_DatasetCSV' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, encoding='cp1252', index_col=None, header=0, low_memory=False)\n",
    "    li.append(df)\n",
    "    print(\"Read Completed for \", filename)\n",
    "\n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "df = df.rename(columns={' Label': 'Label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dfb3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa69de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c5f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with labels other than 'BENIGN' and 'DDoS'\n",
    "df = df[df['Label'].isin(['BENIGN', 'DDoS'])]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "# Display the updated label counts\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d5e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f972f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop na values and reset index\n",
    "data_clean = df.dropna().reset_index()\n",
    "\n",
    "# Checkng for DUPLICATE values\n",
    "data_clean.drop_duplicates(keep='first', inplace = True)\n",
    "\n",
    "data_clean['Label'].value_counts()\n",
    "\n",
    "print(\"Read {} rows.\".format(len(data_clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "# label encoding\n",
    "labelencoder = LabelEncoder()\n",
    "data_clean['Label'] = labelencoder.fit_transform(data_clean['Label'])\n",
    "\n",
    "data_clean['Label'].value_counts()\n",
    "data = data_clean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Drop non-numeric columns if necessary\n",
    "data = data.drop(columns=[ 'index'])  # Adjust column names as needed\n",
    "\n",
    "# Handle infinities\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaNs with column mean\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# Check for any remaining NaNs\n",
    "print(\"Remaining NaNs:\", data.isna().sum().sum())\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36004c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5454492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "print(\"ETC\")\n",
    "dt = ExtraTreesClassifier(n_estimators=300, random_state=5, max_depth=30)\n",
    "\n",
    "yy =  data['Label'].values\n",
    "XX =data.drop(columns=['Label'])\n",
    "\n",
    "\n",
    "# Training the model\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "dt.fit(XX,yy)\n",
    "# Get the feature importances\n",
    "feature_importances = dt.feature_importances_\n",
    "\n",
    "# Create a DataFrame with feature names and importances\n",
    "df_feature_importances = pd.DataFrame({'Feature': XX.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "df_feature_importances = df_feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Extract the top 30 important features\n",
    "selected_features = df_feature_importances.head(30)['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff233ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features.append('Label')\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da5a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the selected features\n",
    "data = data[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98972c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c28f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_insdn = data\n",
    "# Display the shape of the random sample\n",
    "print(data_insdn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c88935",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_insdn['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ab4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cleaned data sample to csv\n",
    "data_insdn.to_csv('cleansample_insdn.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
