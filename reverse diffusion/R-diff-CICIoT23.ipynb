{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7891c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load the data\n",
    "data_clean = pd.read_csv('cleansample_ciciot23.csv')\n",
    "\n",
    "# Sample 45000 rows from the data\n",
    "df = data_clean.sample(n=50000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d66faa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>LLC</th>\n",
       "      <th>TCP</th>\n",
       "      <th>UDP</th>\n",
       "      <th>DHCP</th>\n",
       "      <th>ARP</th>\n",
       "      <th>ICMP</th>\n",
       "      <th>IGMP</th>\n",
       "      <th>IPv</th>\n",
       "      <th>Tot sum</th>\n",
       "      <th>...</th>\n",
       "      <th>ece_flag_number</th>\n",
       "      <th>Time_To_Live</th>\n",
       "      <th>Rate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>psh_flag_number</th>\n",
       "      <th>ack_flag_number</th>\n",
       "      <th>cwr_flag_number</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>636342</th>\n",
       "      <td>25.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.70</td>\n",
       "      <td>45.588031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791919</th>\n",
       "      <td>20.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>21335.286637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554820</th>\n",
       "      <td>21.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>19542.021153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416904</th>\n",
       "      <td>19.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.64</td>\n",
       "      <td>19084.102284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273907</th>\n",
       "      <td>32.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.80</td>\n",
       "      <td>725.118683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Header_Length  LLC   TCP   UDP  DHCP  ARP  ICMP  IGMP  IPv  Tot sum  \\\n",
       "636342          25.20  1.0  0.70  0.30   0.0  0.0   0.0   0.0  1.0     1128   \n",
       "791919          20.00  1.0  1.00  0.00   0.0  0.0   0.0   0.0  1.0     6000   \n",
       "554820          21.28  1.0  1.00  0.00   0.0  0.0   0.0   0.0  1.0     6000   \n",
       "416904          19.88  1.0  0.99  0.01   0.0  0.0   0.0   0.0  1.0     6093   \n",
       "273907          32.00  1.0  1.00  0.00   0.0  0.0   0.0   0.0  1.0     9359   \n",
       "\n",
       "        ...  ece_flag_number  Time_To_Live          Rate  fin_flag_number  \\\n",
       "636342  ...              0.0         85.70     45.588031              0.0   \n",
       "791919  ...              0.0         64.00  21335.286637              0.0   \n",
       "554820  ...              0.0         64.00  19542.021153              0.0   \n",
       "416904  ...              0.0         64.64  19084.102284              0.0   \n",
       "273907  ...              0.0        130.80    725.118683              0.0   \n",
       "\n",
       "        syn_flag_number  rst_flag_number  psh_flag_number  ack_flag_number  \\\n",
       "636342             0.20             0.00              0.2             0.60   \n",
       "791919             0.82             0.18              0.0             0.00   \n",
       "554820             1.00             0.00              0.0             0.32   \n",
       "416904             0.99             0.00              0.0             0.00   \n",
       "273907             0.00             0.00              0.1             1.00   \n",
       "\n",
       "        cwr_flag_number  Label  \n",
       "636342              0.0      0  \n",
       "791919              0.0      1  \n",
       "554820              0.0      1  \n",
       "416904              0.0      1  \n",
       "273907              0.0      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d70acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 15198.248046875\n",
      "Epoch 2/50, Loss: 4794.9453125\n",
      "Epoch 3/50, Loss: 2073.04052734375\n",
      "Epoch 4/50, Loss: 1166.8824462890625\n",
      "Epoch 5/50, Loss: 1103.0015869140625\n",
      "Epoch 6/50, Loss: 813.5145874023438\n",
      "Epoch 7/50, Loss: 818.8939819335938\n",
      "Epoch 8/50, Loss: 427.78118896484375\n",
      "Epoch 9/50, Loss: 435.6746520996094\n",
      "Epoch 10/50, Loss: 313.1453857421875\n",
      "Epoch 11/50, Loss: 231.5169219970703\n",
      "Epoch 12/50, Loss: 429.9721374511719\n",
      "Epoch 13/50, Loss: 364.1856689453125\n",
      "Epoch 14/50, Loss: 193.2771759033203\n",
      "Epoch 15/50, Loss: 198.85357666015625\n",
      "Epoch 16/50, Loss: 400.94342041015625\n",
      "Epoch 17/50, Loss: 136.79483032226562\n",
      "Epoch 18/50, Loss: 128.87208557128906\n",
      "Epoch 19/50, Loss: 118.69204711914062\n",
      "Epoch 20/50, Loss: 191.47357177734375\n",
      "Epoch 21/50, Loss: 107.09317016601562\n",
      "Epoch 22/50, Loss: 293.2994689941406\n",
      "Epoch 23/50, Loss: 240.05628967285156\n",
      "Epoch 24/50, Loss: 80.39372253417969\n",
      "Epoch 25/50, Loss: 138.4593048095703\n",
      "Epoch 26/50, Loss: 425.3372497558594\n",
      "Epoch 27/50, Loss: 95.53495025634766\n",
      "Epoch 28/50, Loss: 59.42501449584961\n",
      "Epoch 29/50, Loss: 139.91873168945312\n",
      "Epoch 30/50, Loss: 451.98443603515625\n",
      "Epoch 31/50, Loss: 272.6169128417969\n",
      "Epoch 32/50, Loss: 258.8473205566406\n",
      "Epoch 33/50, Loss: 471.7593994140625\n",
      "Epoch 34/50, Loss: 155.23138427734375\n",
      "Epoch 35/50, Loss: 617.0108642578125\n",
      "Epoch 36/50, Loss: 342.6792907714844\n",
      "Epoch 37/50, Loss: 212.83358764648438\n",
      "Epoch 38/50, Loss: 98.34156799316406\n",
      "Epoch 39/50, Loss: 334.6023254394531\n",
      "Epoch 40/50, Loss: 602.9730224609375\n",
      "Epoch 41/50, Loss: 264.57818603515625\n",
      "Epoch 42/50, Loss: 169.07357788085938\n",
      "Epoch 43/50, Loss: 67.67179107666016\n",
      "Epoch 44/50, Loss: 518.0733032226562\n",
      "Epoch 45/50, Loss: 351.9549560546875\n",
      "Epoch 46/50, Loss: 155.3616180419922\n",
      "Epoch 47/50, Loss: 124.9091796875\n",
      "Epoch 48/50, Loss: 271.0924072265625\n",
      "Epoch 49/50, Loss: 196.38587951660156\n",
      "Epoch 50/50, Loss: 86.00471496582031\n",
      "OOD Samples Shape: (20000, 30)\n",
      "OOD Labels Shape: (20000, 1)\n",
      "Sample OOD Labels: [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Separate features and labels from the DataFrame\n",
    "features = df.drop(columns=[\"Label\"]).values  # 30 features\n",
    "labels = df[\"Label\"].values  # Label column (last column)\n",
    "\n",
    "# No scaling is applied, keeping the features in their original scale\n",
    "features_scaled = features  \n",
    "\n",
    "# Parameters for the diffusion model\n",
    "timesteps = 1000\n",
    "embedding_dim = 128  # Adjust based on your data\n",
    "input_dim = features_scaled.shape[1]  \n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "# Noise schedule (betas for the diffusion process)\n",
    "def get_noise_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return np.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "betas = get_noise_schedule(timesteps)\n",
    "\n",
    "# Forward noise process (adding noise to data)\n",
    "def forward_noise(x, t):\n",
    "    noise = np.random.normal(size=x.shape)\n",
    "    return np.sqrt(1 - betas[t]) * x + np.sqrt(betas[t]) * noise\n",
    "\n",
    "# Build conditional reverse model (MLP-based), with labels\n",
    "def build_conditional_reverse_model(input_dim, embedding_dim, num_classes):\n",
    "    input_data = layers.Input(shape=(input_dim,))\n",
    "    input_label = layers.Input(shape=(num_classes,))  # Labels one-hot encoded\n",
    "\n",
    "    # Concatenate data and label\n",
    "    x = layers.concatenate([input_data, input_label])\n",
    "    x = layers.Dense(embedding_dim, activation='relu')(x)\n",
    "    x = layers.Dense(embedding_dim, activation='relu')(x)\n",
    "    output = layers.Dense(input_dim)(x)  # Output is the denoised (or OOD) data\n",
    "\n",
    "    model = models.Model(inputs=[input_data, input_label], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Loss function for reverse diffusion\n",
    "def diffusion_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Training the reverse diffusion model with label conditioning\n",
    "def train_conditional_reverse_diffusion_model(model, data, labels, timesteps, epochs=50, batch_size=32):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)  # Lower learning rate\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for step in range(0, len(data), batch_size):\n",
    "            x_batch = data[step:step+batch_size]\n",
    "            y_batch = labels[step:step+batch_size]\n",
    "            \n",
    "            t = np.random.randint(0, timesteps)  # Randomly choose a timestep\n",
    "            noisy_data = forward_noise(x_batch, t)  # Add noise to data\n",
    "\n",
    "            # Train model to predict the clean data from noisy data\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = model([noisy_data, y_batch], training=True)\n",
    "                loss = diffusion_loss(x_batch, predictions)\n",
    "            \n",
    "            gradients = tape.gradient(loss, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.numpy()}\")\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "labels_one_hot = tf.keras.utils.to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "# Build the conditional reverse model\n",
    "reverse_model = build_conditional_reverse_model(input_dim, embedding_dim, num_classes)\n",
    "\n",
    "# Train reverse model with labeled data\n",
    "train_conditional_reverse_diffusion_model(reverse_model, features_scaled, labels_one_hot, timesteps, epochs=50)\n",
    "\n",
    "# Generate OOD samples without scaling, with labels in (10000, 1) format\n",
    "def generate_conditional_ood_samples_with_labels(model, num_samples, input_dim, num_classes, timesteps):\n",
    "    # Randomly sample classes as integers\n",
    "    random_classes = np.random.randint(0, num_classes, num_samples)  # Labels as integers, not one-hot\n",
    "    \n",
    "    # Start with random noise\n",
    "    noise = np.random.normal(size=(num_samples, input_dim))  # Keep the noise in the original scale\n",
    "    \n",
    "    # Iteratively apply reverse diffusion\n",
    "    for t in reversed(range(timesteps)):\n",
    "        noise = model([noise, tf.keras.utils.to_categorical(random_classes, num_classes=num_classes)], training=False)  # Predict the clean data\n",
    "        # Optionally, can add noise back to keep it stochastic\n",
    "        noise = np.sqrt(1 - betas[t]) * noise + np.sqrt(betas[t]) * np.random.normal(size=noise.shape)\n",
    "    \n",
    "    # Return OOD samples and labels in shape (10000, 1)\n",
    "    return noise, random_classes.reshape(-1, 1)  # Labels as (10000, 1) with values 0 or 1\n",
    "\n",
    "# Generate OOD samples with labels in (10000, 1) format\n",
    "ood_samples, ood_labels = generate_conditional_ood_samples_with_labels(reverse_model, num_samples=20000, input_dim=input_dim, num_classes=num_classes, timesteps=timesteps)\n",
    "\n",
    "# Check the output shape\n",
    "print(\"OOD Samples Shape:\", ood_samples.shape)  # Should be (10000, input_dim)\n",
    "print(\"OOD Labels Shape:\", ood_labels.shape)    # Should be (10000, 1)\n",
    "print(\"Sample OOD Labels:\", ood_labels[:10])\n",
    "\n",
    "# Create a Pandas DataFrame for OOD samples and labels\n",
    "ood_samples_np = ood_samples.numpy() if isinstance(ood_samples, tf.Tensor) else ood_samples\n",
    "ood_labels_np = ood_labels.numpy() if isinstance(ood_labels, tf.Tensor) else ood_labels\n",
    "\n",
    "# Define column names for OOD samples based on your original dataset\n",
    "column_names = df.drop(columns=[\"Label\"]).columns.tolist()\n",
    "\n",
    "# Create a Pandas DataFrame for the OOD samples\n",
    "ood_samples_df = pd.DataFrame(ood_samples_np, columns=column_names)\n",
    "ood_labels_df = pd.DataFrame(ood_labels_np, columns=['Label'])\n",
    "\n",
    "# Concatenate the OOD samples and labels\n",
    "ood_combined_df = pd.concat([ood_samples_df, ood_labels_df], axis=1)\n",
    "\n",
    "# Save the OOD samples to CSV\n",
    "ood_combined_df.to_csv('ood_samples_IoT.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c49246b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf=pd.read_csv('ood_samples_IoT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d009788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>LLC</th>\n",
       "      <th>TCP</th>\n",
       "      <th>UDP</th>\n",
       "      <th>DHCP</th>\n",
       "      <th>ARP</th>\n",
       "      <th>ICMP</th>\n",
       "      <th>IGMP</th>\n",
       "      <th>IPv</th>\n",
       "      <th>Tot sum</th>\n",
       "      <th>...</th>\n",
       "      <th>ece_flag_number</th>\n",
       "      <th>Time_To_Live</th>\n",
       "      <th>Rate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>psh_flag_number</th>\n",
       "      <th>ack_flag_number</th>\n",
       "      <th>cwr_flag_number</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109.77064</td>\n",
       "      <td>1.748207</td>\n",
       "      <td>7.294745</td>\n",
       "      <td>-6.981845</td>\n",
       "      <td>-1.471898</td>\n",
       "      <td>0.035954</td>\n",
       "      <td>4.584979</td>\n",
       "      <td>11.591014</td>\n",
       "      <td>-0.087753</td>\n",
       "      <td>1692.4153</td>\n",
       "      <td>...</td>\n",
       "      <td>9.731266</td>\n",
       "      <td>608.89246</td>\n",
       "      <td>882.91110</td>\n",
       "      <td>-3.454185</td>\n",
       "      <td>8.889511</td>\n",
       "      <td>7.784659</td>\n",
       "      <td>3.099734</td>\n",
       "      <td>6.600990</td>\n",
       "      <td>-13.527213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.16375</td>\n",
       "      <td>1.488363</td>\n",
       "      <td>5.336557</td>\n",
       "      <td>-5.054549</td>\n",
       "      <td>-0.907123</td>\n",
       "      <td>-0.507603</td>\n",
       "      <td>2.840215</td>\n",
       "      <td>8.999970</td>\n",
       "      <td>0.457124</td>\n",
       "      <td>1251.7667</td>\n",
       "      <td>...</td>\n",
       "      <td>7.142943</td>\n",
       "      <td>450.51360</td>\n",
       "      <td>634.31287</td>\n",
       "      <td>-3.228183</td>\n",
       "      <td>6.522609</td>\n",
       "      <td>5.677407</td>\n",
       "      <td>2.075346</td>\n",
       "      <td>5.244236</td>\n",
       "      <td>-9.897901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.31266</td>\n",
       "      <td>1.472496</td>\n",
       "      <td>5.331750</td>\n",
       "      <td>-5.082406</td>\n",
       "      <td>-0.918540</td>\n",
       "      <td>-0.499593</td>\n",
       "      <td>2.864492</td>\n",
       "      <td>9.031106</td>\n",
       "      <td>0.451670</td>\n",
       "      <td>1253.8086</td>\n",
       "      <td>...</td>\n",
       "      <td>7.135342</td>\n",
       "      <td>451.23407</td>\n",
       "      <td>635.23080</td>\n",
       "      <td>-3.234776</td>\n",
       "      <td>6.537467</td>\n",
       "      <td>5.675081</td>\n",
       "      <td>2.065433</td>\n",
       "      <td>5.280328</td>\n",
       "      <td>-9.949425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.74574</td>\n",
       "      <td>1.477105</td>\n",
       "      <td>5.278973</td>\n",
       "      <td>-5.059063</td>\n",
       "      <td>-0.915550</td>\n",
       "      <td>-0.503525</td>\n",
       "      <td>2.815097</td>\n",
       "      <td>8.978140</td>\n",
       "      <td>0.457655</td>\n",
       "      <td>1244.9521</td>\n",
       "      <td>...</td>\n",
       "      <td>7.094887</td>\n",
       "      <td>448.06384</td>\n",
       "      <td>630.49664</td>\n",
       "      <td>-3.196458</td>\n",
       "      <td>6.476322</td>\n",
       "      <td>5.646110</td>\n",
       "      <td>2.052216</td>\n",
       "      <td>5.240566</td>\n",
       "      <td>-9.860132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.89248</td>\n",
       "      <td>1.475915</td>\n",
       "      <td>5.312867</td>\n",
       "      <td>-5.073564</td>\n",
       "      <td>-0.917409</td>\n",
       "      <td>-0.495399</td>\n",
       "      <td>2.824968</td>\n",
       "      <td>8.977908</td>\n",
       "      <td>0.467393</td>\n",
       "      <td>1247.0093</td>\n",
       "      <td>...</td>\n",
       "      <td>7.098178</td>\n",
       "      <td>448.83362</td>\n",
       "      <td>631.61330</td>\n",
       "      <td>-3.215761</td>\n",
       "      <td>6.514331</td>\n",
       "      <td>5.666192</td>\n",
       "      <td>2.092775</td>\n",
       "      <td>5.216328</td>\n",
       "      <td>-9.863365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Header_Length       LLC       TCP       UDP      DHCP       ARP      ICMP  \\\n",
       "0      109.77064  1.748207  7.294745 -6.981845 -1.471898  0.035954  4.584979   \n",
       "1       81.16375  1.488363  5.336557 -5.054549 -0.907123 -0.507603  2.840215   \n",
       "2       81.31266  1.472496  5.331750 -5.082406 -0.918540 -0.499593  2.864492   \n",
       "3       80.74574  1.477105  5.278973 -5.059063 -0.915550 -0.503525  2.815097   \n",
       "4       80.89248  1.475915  5.312867 -5.073564 -0.917409 -0.495399  2.824968   \n",
       "\n",
       "        IGMP       IPv    Tot sum  ...  ece_flag_number  Time_To_Live  \\\n",
       "0  11.591014 -0.087753  1692.4153  ...         9.731266     608.89246   \n",
       "1   8.999970  0.457124  1251.7667  ...         7.142943     450.51360   \n",
       "2   9.031106  0.451670  1253.8086  ...         7.135342     451.23407   \n",
       "3   8.978140  0.457655  1244.9521  ...         7.094887     448.06384   \n",
       "4   8.977908  0.467393  1247.0093  ...         7.098178     448.83362   \n",
       "\n",
       "        Rate  fin_flag_number  syn_flag_number  rst_flag_number  \\\n",
       "0  882.91110        -3.454185         8.889511         7.784659   \n",
       "1  634.31287        -3.228183         6.522609         5.677407   \n",
       "2  635.23080        -3.234776         6.537467         5.675081   \n",
       "3  630.49664        -3.196458         6.476322         5.646110   \n",
       "4  631.61330        -3.215761         6.514331         5.666192   \n",
       "\n",
       "   psh_flag_number  ack_flag_number  cwr_flag_number  Label  \n",
       "0         3.099734         6.600990       -13.527213      0  \n",
       "1         2.075346         5.244236        -9.897901      1  \n",
       "2         2.065433         5.280328        -9.949425      1  \n",
       "3         2.052216         5.240566        -9.860132      1  \n",
       "4         2.092775         5.216328        -9.863365      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ed6fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
